{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of cleaned data:\n",
      "            input                                             output\n",
      "0  acessibilidade  Luz mais baixa, gostaria de uma luz mais baixa...\n",
      "1           agora  Agora, eu quero fazer isso agora, ‚è∞\\nEsperar, ...\n",
      "2       agradecer  Muito obrigado, quero agradecer de cora√ß√£o, üôè\\...\n",
      "3           ajuda  Preciso de Ajuda, eu preciso de ajuda, ü§≤\\nMe D...\n",
      "4   ajuda emocoes  Falar Sobre Sentimentos, eu quero falar sobre ...\n",
      "\n",
      "Original dataset size: 6578\n",
      "Cleaned dataset size: 5815\n",
      "Removed entries: 763\n",
      "Duplicate inputs removed: 763\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import unidecode\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Remove accents and special characters, convert to lowercase\"\"\"\n",
    "    text = text.lower()\n",
    "    text = unidecode.unidecode(text)\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def validate_output(output):\n",
    "    \"\"\"Check if output has exactly 5 lines\"\"\"\n",
    "    lines = output.strip().split('\\n')\n",
    "    return len(lines) == 5\n",
    "\n",
    "\n",
    "df = pd.read_csv('../cleaned_dataset3.csv')\n",
    "\n",
    "cleaned_data = {} \n",
    "for _, row in df.iterrows():\n",
    "    input_text = clean_text(row['input'])\n",
    "    output_text = row['output']\n",
    "    \n",
    "    if validate_output(output_text) and input_text not in cleaned_data:\n",
    "        cleaned_data[input_text] = output_text\n",
    "\n",
    "cleaned_df = pd.DataFrame([\n",
    "    {'input': k, 'output': v} for k, v in cleaned_data.items()\n",
    "])\n",
    "\n",
    "cleaned_df.to_csv('../cleaned_dataset3.csv', index=False)\n",
    "\n",
    "print(\"Sample of cleaned data:\")\n",
    "print(cleaned_df.head())\n",
    "print(f\"\\nOriginal dataset size: {len(df)}\")\n",
    "print(f\"Cleaned dataset size: {len(cleaned_df)}\")\n",
    "print(f\"Removed entries: {len(df) - len(cleaned_df)}\")\n",
    "print(f\"Duplicate inputs removed: {len(df) - len(cleaned_data)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ic-dataset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
